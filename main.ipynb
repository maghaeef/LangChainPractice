{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the environment -> openai api key\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8744/1960464751.py:2: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
      "  llm = OpenAI(temperature=0.6)\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(temperature=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\"Shah\\'s Palace: A Taste of Persia\"'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = llm(\"I want to open a restaurant for Persian food. Suggest a fency name for this.\")\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to open a restaurant for Persian food. Suggest a fency name for this.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template=\"I want to open a restaurant for {cuisine} food. Suggest a fency name for this.\")\n",
    "\n",
    "prompt_template_name.format(cuisine=\"Persian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8744/3335593058.py:3: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm=llm, prompt=prompt_template_name)\n",
      "/tmp/ipykernel_8744/3335593058.py:4: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  chain.run('Persian')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n\"Persian Palace\" '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template_name)\n",
    "chain.run('Persian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Hummus with pita bread\n",
      "2. Falafel platter\n",
      "3. Lamb kebab\n",
      "4. Chicken shawarma\n",
      "5. Beef kofta\n",
      "6. Persian rice with saffron\n",
      "7. Baba ghanoush\n",
      "8. Dolma (stuffed grape leaves)\n",
      "9. Fesenjan (pomegranate and walnut stew)\n",
      "10. Ghormeh sabzi (herb and beef stew)\n",
      "11. Kashk-e bademjan (eggplant dip)\n",
      "12. Joojeh kabab (grilled chicken skewers)\n",
      "13. Tahchin (saffron rice cake)\n",
      "14. Mast-o-khiar (cucumber and yogurt dip)\n",
      "15. Baghali polo (dill and lima bean rice).\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(temperature=0.6)\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template=\"I want to open a restaurant for {cuisine} food. Suggest a fency name for this.\")\n",
    "\n",
    "\n",
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables=['restaurant_name'],\n",
    "    template='Suggest some menu items for {restaurant_name}. Return it as comma separated list.'\n",
    ")\n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "name_chain = LLMChain(llm=llm, prompt=prompt_template_name)\n",
    "items_chain = LLMChain(llm=llm, prompt=prompt_template_items)\n",
    "\n",
    "\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "chain = SimpleSequentialChain(chains=[name_chain, items_chain])\n",
    "response = chain.run(\"Persian\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8744/3404816473.py:25: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  chain({'cuisine':'Persian'})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cuisine': 'Persian',\n",
       " 'restaurant_name': '\\n\\n\"Saffron Palace\"',\n",
       " 'items': '\\n\\n1. Saffron Chicken Tikka Masala\\n2. Lamb Biryani \\n3. Vegetable Samosas \\n4. Tandoori Shrimp \\n5. Palak Paneer \\n6. Naan Bread \\n7. Chicken Korma \\n8. Aloo Gobi \\n9. Mango Lassi \\n10. Gulab Jamun \\n11. Mixed Vegetable Curry \\n12. Lamb Rogan Josh \\n13. Chicken Vindaloo \\n14. Gajar Halwa \\n15. Saffron Rice.'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(temperature=0.6)\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template=\"I want to open a restaurant for {cuisine} food. Suggest a fency name for this.\")\n",
    "\n",
    "\n",
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables=['restaurant_name'],\n",
    "    template='Suggest some menu items for {restaurant_name}. Return it as comma separated list.'\n",
    ")\n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "name_chain = LLMChain(llm=llm, prompt=prompt_template_name, output_key='restaurant_name') # output_key is added\n",
    "items_chain = LLMChain(llm=llm, prompt=prompt_template_items, output_key='items')         # output_key is added\n",
    "\n",
    "from langchain.chains import SequentialChain\n",
    "chain = SequentialChain(chains=[name_chain, items_chain], \n",
    "                        input_variables=['cuisine'], \n",
    "                        output_variables=['restaurant_name', 'items'])\n",
    "\n",
    "chain({'cuisine':'Persian'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the terminal\n",
    "\n",
    "# streamlit run app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
