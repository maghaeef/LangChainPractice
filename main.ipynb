{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# setting up the environment -> openai api key\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(temperature=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\"Shah\\'s Feast: A Persian Culinary Experience\"'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = llm(\"I want to open a restaurant for Persian food. Suggest a fency name for this.\")\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to open a restaurant for Persian food. Suggest a fency name for this.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template=\"I want to open a restaurant for {cuisine} food. Suggest a fency name for this.\")\n",
    "\n",
    "prompt_template_name.format(cuisine=\"Persian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\"Saffron Palace\" '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template_name)\n",
    "chain.run('Persian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Saffron Chicken Tikka Masala\n",
      "2. Vegetable Biryani\n",
      "3. Lamb Rogan Josh\n",
      "4. Paneer Butter Masala\n",
      "5. Tandoori Shrimp\n",
      "6. Dal Makhani\n",
      "7. Chicken Korma\n",
      "8. Aloo Gobi\n",
      "9. Naan Bread\n",
      "10. Mango Lassi\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(temperature=0.6)\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template=\"I want to open a restaurant for {cuisine} food. Suggest a fency name for this.\")\n",
    "\n",
    "\n",
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables=['restaurant_name'],\n",
    "    template='Suggest some menu items for {restaurant_name}. Return it as comma separated list.'\n",
    ")\n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "name_chain = LLMChain(llm=llm, prompt=prompt_template_name)\n",
    "items_chain = LLMChain(llm=llm, prompt=prompt_template_items)\n",
    "\n",
    "\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "chain = SimpleSequentialChain(chains=[name_chain, items_chain])\n",
    "response = chain.run(\"Persian\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cuisine': 'Persian',\n",
       " 'restaurant_name': '\\n\"Persian Palate\" ',\n",
       " 'items': '\\n\\n1. Hummus with Pita Bread\\n2. Falafel Platter\\n3. Ghormeh Sabzi (Herb Stew)\\n4. Chicken Kabob\\n5. Lamb Kebab\\n6. Tahchin (Saffron Rice Cake)\\n7. Dolmeh (Stuffed Grape Leaves)\\n8. Kashk-e Bademjan (Eggplant Dip)\\n9. Ash-e Reshteh (Noodle Soup)\\n10. Shirazi Salad (Cucumber, Tomato, and Onion Salad)\\n11. Zereshk Polo (Barberry Rice)\\n12. Fesenjan (Pomegranate Walnut Stew)\\n13. Baghali Polo (Lima Bean Rice)\\n14. Saffron Ice Cream\\n15. Baklava (Sweet Pastry)'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(temperature=0.6)\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template=\"I want to open a restaurant for {cuisine} food. Suggest a fency name for this.\")\n",
    "\n",
    "\n",
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables=['restaurant_name'],\n",
    "    template='Suggest some menu items for {restaurant_name}. Return it as comma separated list.'\n",
    ")\n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "name_chain = LLMChain(llm=llm, prompt=prompt_template_name, output_key='restaurant_name') # output_key is added\n",
    "items_chain = LLMChain(llm=llm, prompt=prompt_template_items, output_key='items')         # output_key is added\n",
    "\n",
    "from langchain.chains import SequentialChain\n",
    "chain = SequentialChain(chains=[name_chain, items_chain], \n",
    "                        input_variables=['cuisine'], \n",
    "                        output_variables=['restaurant_name', 'items'])\n",
    "\n",
    "chain({'cuisine':'Persian'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the terminal\n",
    "\n",
    "# streamlit run app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
