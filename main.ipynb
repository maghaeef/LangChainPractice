{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# setting up the environment -> openai api key\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(temperature=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\"Shah\\'s Feast: A Persian Culinary Experience\"'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = llm(\"I want to open a restaurant for Persian food. Suggest a fency name for this.\")\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to open a restaurant for Persian food. Suggest a fency name for this.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template=\"I want to open a restaurant for {cuisine} food. Suggest a fency name for this.\")\n",
    "\n",
    "prompt_template_name.format(cuisine=\"Persian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\"Saffron Palace\" '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template_name)\n",
    "chain.run('Persian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Saffron Chicken Tikka Masala\n",
      "2. Vegetable Biryani\n",
      "3. Lamb Rogan Josh\n",
      "4. Paneer Butter Masala\n",
      "5. Tandoori Shrimp\n",
      "6. Dal Makhani\n",
      "7. Chicken Korma\n",
      "8. Aloo Gobi\n",
      "9. Naan Bread\n",
      "10. Mango Lassi\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(temperature=0.6)\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template=\"I want to open a restaurant for {cuisine} food. Suggest a fency name for this.\")\n",
    "\n",
    "\n",
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables=['restaurant_name'],\n",
    "    template='Suggest some menu items for {restaurant_name}. Return it as comma separated list.'\n",
    ")\n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "name_chain = LLMChain(llm=llm, prompt=prompt_template_name)\n",
    "items_chain = LLMChain(llm=llm, prompt=prompt_template_items)\n",
    "\n",
    "\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "chain = SimpleSequentialChain(chains=[name_chain, items_chain])\n",
    "response = chain.run(\"Persian\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cuisine': 'Persian',\n",
       " 'restaurant_name': '\\n\"Persian Palate\" ',\n",
       " 'items': '\\n\\n1. Hummus with Pita Bread\\n2. Falafel Platter\\n3. Ghormeh Sabzi (Herb Stew)\\n4. Chicken Kabob\\n5. Lamb Kebab\\n6. Tahchin (Saffron Rice Cake)\\n7. Dolmeh (Stuffed Grape Leaves)\\n8. Kashk-e Bademjan (Eggplant Dip)\\n9. Ash-e Reshteh (Noodle Soup)\\n10. Shirazi Salad (Cucumber, Tomato, and Onion Salad)\\n11. Zereshk Polo (Barberry Rice)\\n12. Fesenjan (Pomegranate Walnut Stew)\\n13. Baghali Polo (Lima Bean Rice)\\n14. Saffron Ice Cream\\n15. Baklava (Sweet Pastry)'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(temperature=0.6)\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template=\"I want to open a restaurant for {cuisine} food. Suggest a fency name for this.\")\n",
    "\n",
    "\n",
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables=['restaurant_name'],\n",
    "    template='Suggest some menu items for {restaurant_name}. Return it as comma separated list.'\n",
    ")\n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "name_chain = LLMChain(llm=llm, prompt=prompt_template_name, output_key='restaurant_name') # output_key is added\n",
    "items_chain = LLMChain(llm=llm, prompt=prompt_template_items, output_key='items')         # output_key is added\n",
    "\n",
    "from langchain.chains import SequentialChain\n",
    "chain = SequentialChain(chains=[name_chain, items_chain], \n",
    "                        input_variables=['cuisine'], \n",
    "                        output_variables=['restaurant_name', 'items'])\n",
    "\n",
    "chain({'cuisine':'Persian'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the terminal\n",
    "\n",
    "# streamlit run app.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Agents in LangChain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wikipedia numexpr -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m We can use Wikipedia to find information about Elon Musk's birthdate and age.\n",
      "Action: wikipedia\n",
      "Action Input: Elon Musk\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPage: Elon Musk\n",
      "Summary: Elon Reeve Musk ( EE-lon; born June 28, 1971) is a businessman known for his leadership of Tesla, SpaceX, and X (formerly Twitter). Since 2025, he has been a senior advisor to United States president Donald Trump and the de facto head of the Department of Government Efficiency (DOGE). Musk has been considered the wealthiest person in the world since 2021; as of May 2025, Forbes estimates his net worth to be US$424.7 billion. He was named Time magazine's Person of the Year in 2021.\n",
      "Born to a wealthy family in Pretoria, South Africa, Musk emigrated in 1989 to Canada. He graduated from the University of Pennsylvania in the U.S. before moving to California to pursue business ventures. In 1995, Musk co-founded the software company Zip2. Following its sale in 1999, he co-founded X.com, an online payment company that later merged to form PayPal, which was acquired by eBay in 2002. That year, Musk also became a U.S. citizen.\n",
      "In 2002, Musk founded the space technology company SpaceX, becoming its CEO and chief engineer; the company has since led innovations in reusable rockets and commercial spaceflight. Musk joined the automaker Tesla as an early investor in 2004 and became its CEO and product architect in 2008; it has since become a leader in electric vehicles. In 2015, he co-founded OpenAI to advance artificial intelligence research but later left; growing discontent with the organization's direction in the 2020s led him to establish xAI. In 2022, he acquired the social network Twitter, implementing significant changes and rebranding it as X in 2023. In January 2025, he was appointed head of Trump's newly created DOGE. His other businesses include the neurotechnology company Neuralink, which he co-founded in 2016, and the tunneling company the Boring Company, which he founded in 2017.\n",
      "Musk's political activities and views have made him a polarizing figure. He has been criticized for making unscientific and misleading statements, including COVID-19 misinformation and promoting conspiracy theories, and affirming antisemitic, racist, and transphobic comments. His acquisition of Twitter was controversial due to a subsequent increase in hate speech and the spread of misinformation on the service. Especially since the 2024 U.S. presidential election, Musk has been heavily involved in politics as a vocal supporter of Trump. Musk was the largest donor in the 2024 U.S. presidential election and is a supporter of global far-right figures, causes, and political parties. His role in the second Trump administration, particularly in regards to DOGE, has attracted public backlash.\n",
      "\n",
      "\n",
      "\n",
      "Page: Wealth of Elon Musk\n",
      "Summary: Elon Musk is the wealthiest person in the world, with an estimated net worth of US$381 billion as of May 2025, according to the Bloomberg Billionaires Index, and $424.7 billion according to Forbes, primarily from his ownership stakes in Tesla and SpaceX. \n",
      "Having been first listed on the Forbes Billionaires List in 2012, around 75% of Musk's wealth was derived from Tesla stock in November 2020. Describing himself as \"cash poor\", he became the first person in the world to have a net worth above $300 billion a year later. By December 2024, he became the first person to reach a net worth of $400 billion.\n",
      "\n",
      "\n",
      "\n",
      "Page: Elon Musk salute controversy\n",
      "Summary: On January 20, 2025, while speaking at a rally celebrating U.S. president Donald Trump's second inauguration, businessman and political figure Elon Musk twice made a gesture interpreted by many as a Nazi or a fascist Roman salute.\n",
      "It was widely condemned as an intentional Nazi salute in Germany, where making such gestures is illegal. The Anti-Defamation League said it was not a Nazi salute, but other Jewish organizations disagreed and condemned the salute. American public opinion was divided on partisan lines as to whether it was a fascist salute. Musk dismissed the accusations of Nazi sympathies, deriding them as \"dirty tricks\" and a \"tired\" attack. Neo-Nazi and whi\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m We can use the information from the Wikipedia page to calculate Elon Musk's age in 2030.\n",
      "Action: Calculator\n",
      "Action Input: 2030 - 1971\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 59\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Now that we know Elon Musk's age in 2030, we can calculate his birth year.\n",
      "Action: Calculator\n",
      "Action Input: 2030 - 59\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 1971\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m We now have Elon Musk's birth year and age in 2030.\n",
      "Final Answer: Elon Musk was born in 1971 and will be 59 years old in 2030.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Elon Musk was born in 1971 and will be 59 years old in 2030.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import AgentType, initialize_agent, load_tools\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0.6)\n",
    "\n",
    "tools = load_tools([\"wikipedia\", \"llm-math\"], llm=llm)\n",
    "\n",
    "agent = initialize_agent(llm=llm,\n",
    "                         tools=tools,\n",
    "                         agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "                         verbose=True) # if you want to see the reasoning process.\n",
    "\n",
    "agent.run(\"When was Elon Musk born and what is his age in 2030?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install google-search-results -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use a search engine to find the answer.\n",
      "Action: Search\n",
      "Action Input: \"GDP of U.S. in 2022\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[\"The U.S. is a country of 50 states covering a vast swath of North America, with Alaska in the northwest and Hawaii extending the nation’s presence into the Pacific Ocean. Major Atlantic Coast cities are New York, a global finance and culture center, and capital Washington, DC. Midwestern metropolis Chicago is known for influential architecture and on the west coast, Los Angeles' Hollywood is famed for filmmaking. ― Google\", 'United States type: Country in North America.', 'United States kgmid: /m/09c7w0.', 'Current-dollar GDP increased 9.2 percent, or $2.15 trillion, in 2022 to a level of $25.46 trillion, compared with an increase of 10.7 percent, ...', 'U.S. GDP for 2022 was 25.744 trillion US dollars, a 9.11% increase from 2021. · U.S. GDP for 2021 was 23.594 trillion US dollars, a 10.65% increase from 2020.', 'Gross Domestic Product (GDP) of the United States ; 2023, $27,720,700,000,000, $22,062,600,000,000 ; 2022, $26,006,900,000,000, $21,443,400,000,000 ; 2021 ...', 'The Gross Domestic Product (GDP) in the United States was worth 27720.71 billion US dollars in 2023, according to official data from the World Bank.', 'Current-dollar GDP increased 9.2 percent, or $2.15 trillion, in 2022 to a level of $25.46 trillion, compared with an increase of 10.7 percent, ...', 'GDP (current US$) - United States. World Bank national accounts data, and OECD National Accounts data files. License : CC BY-4.0', \"As of 2025, it has the world's seventh highest nominal GDP per capita and ninth highest GDP per capita by PPP. The U.S. accounted for 26% of the global economy ...\", 'The U.S. economy contracted at an annualized rate of 0.3% in the first quarter of 2025, marking the first decline since the first quarter of 2022.', 'The nominal GDP per capita in United States of America was $82,769.41 in 2023. The Gini index in United States of America was 41.3 in 2022. The life ...']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use a calculator to find the exact GDP number.\n",
      "Action: Calculator\n",
      "Action Input: 25.744 trillion + 9.11%\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 28089278400000.0\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should convert the answer to a more readable format.\n",
      "Action: Calculator\n",
      "Action Input: 28089278400000.0 in billions\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 28089.2784\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: The GDP of the U.S. in 2022 was $28,089.2784 billion.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The GDP of the U.S. in 2022 was $28,089.2784 billion.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"SERPAPI_API_KEY\"] = os.getenv(\"SERPAPI_API_KEY\")\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
    "\n",
    "agent = initialize_agent(llm=llm,\n",
    "                         tools=tools,\n",
    "                         agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "                         verbose=True) # if you want to see the reasoning process.\n",
    "\n",
    "agent.run(\"what was the GDP of the U.S. in 2022?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Memory** \n",
    "- When we humans talk about a topic, we remember what the conversation is about.\n",
    "- chains by default do not have that memory. -> default=None\n",
    "- Thus, we can make an object and attach it to the chain or to the agent to remember all the prompt-response conversations.\n",
    "- very useful if we are building a chatbot, e.g. customer support.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(chain.memory) # the default of the memory is None. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(temperature=0.6)\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template=\"I want to open a restaurant for {cuisine} food. Suggest a fency name for this.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Shah\\'s Palace: A Taste of Persia\"'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "chain = LLMChain(llm=llm,\n",
    "                 prompt=prompt_template_name,\n",
    "                 memory=memory) # memory is now added to the chain\n",
    "\n",
    "name = chain.run(\"Persian\").strip()\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Stateside Eats\"'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = chain.run(\"American\").strip()\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationBufferMemory(chat_memory=InMemoryChatMessageHistory(messages=[HumanMessage(content='Persian', additional_kwargs={}, response_metadata={}), AIMessage(content='\\n\\n\"Shah\\'s Palace: A Taste of Persia\"', additional_kwargs={}, response_metadata={}), HumanMessage(content='American', additional_kwargs={}, response_metadata={}), AIMessage(content='\\n\\n\"Stateside Eats\"', additional_kwargs={}, response_metadata={})]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Persian\n",
      "AI: \n",
      "\n",
      "\"Shah's Palace: A Taste of Persia\"\n",
      "Human: American\n",
      "AI: \n",
      "\n",
      "\"Stateside Eats\"\n"
     ]
    }
   ],
   "source": [
    "print(chain.memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to keep the cost not very high, we should set a buffer size to avoid sending all the memory to the LLM on every call to the LLM. For example, we can set to consider only the last 5 conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "{history}\n",
      "Human: {input}\n",
      "AI:\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "\n",
    "conv = ConversationChain(llm=OpenAI(temperature=0.7))\n",
    "\n",
    "print(conv.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The first FIFA World Cup was held in 1930 in Uruguay, and the winner was the host country, Uruguay. They defeated Argentina 4-2 in the final.'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.run(\"who won the first world cup?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  The answer to 5+5 is 10.'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.run('what is 5+5?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The captain of the winning team, Uruguay, was José Nasazzi. He was a defender and played for the Uruguayan club Nacional.'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.run(\"who was the captain of the winner?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationBufferMemory(chat_memory=InMemoryChatMessageHistory(messages=[HumanMessage(content='who won the first world cup?', additional_kwargs={}, response_metadata={}), AIMessage(content=' The first FIFA World Cup was held in 1930 in Uruguay, and the winner was the host country, Uruguay. They defeated Argentina 4-2 in the final.', additional_kwargs={}, response_metadata={}), HumanMessage(content='what is 5+5?', additional_kwargs={}, response_metadata={}), AIMessage(content='  The answer to 5+5 is 10.', additional_kwargs={}, response_metadata={}), HumanMessage(content='who was the captain of the winner?', additional_kwargs={}, response_metadata={}), AIMessage(content=' The captain of the winning team, Uruguay, was José Nasazzi. He was a defender and played for the Uruguayan club Nacional.', additional_kwargs={}, response_metadata={})]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: who won the first world cup?\n",
      "AI:  The first FIFA World Cup was held in 1930 in Uruguay, and the winner was the host country, Uruguay. They defeated Argentina 4-2 in the final.\n",
      "Human: what is 5+5?\n",
      "AI:   The answer to 5+5 is 10.\n",
      "Human: who was the captain of the winner?\n",
      "AI:  The captain of the winning team, Uruguay, was José Nasazzi. He was a defender and played for the Uruguayan club Nacional.\n"
     ]
    }
   ],
   "source": [
    "print(conv.memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=1) # only the last conversation is remembered\n",
    "conv = ConversationChain(llm=OpenAI(temperature=0.7),\n",
    "                         memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" The first FIFA World Cup was held in 1930 and was won by the host country, Uruguay. They defeated Argentina in the final match by a score of 4-2. It was a 13-team tournament, with 7 South American teams and 6 European teams participating. The tournament was organized by FIFA and was held in Montevideo, Uruguay's capital city.\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.run(\"who won the first world cup?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 5+5 is 10.'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.run('what is 5+5?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" I'm sorry, I don't have enough context to answer that question. Could you provide more information about which winner you are referring to?\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.run(\"who was the captain of the winner?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
